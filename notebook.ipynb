{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f25d3f",
   "metadata": {},
   "source": [
    "## 1) Load environment variables + initialize Groq client\n",
    "Loads `GROQ_API_KEY` from `.env` and creates a Groq client instance for API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "dotenv_path = find_dotenv(usecwd=True)\n",
    "load_dotenv(dotenv_path=dotenv_path, override=True)\n",
    "\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"GROQ_API_KEY not found. Put it in your .env file.\")\n",
    "\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "model=\"llama-3.1-8b-instant\",\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"hello\"},\n",
    "    ],\n",
    "temperature=0.2,\n",
    "\n",
    "# print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cec827",
   "metadata": {},
   "source": [
    "## 2) (Optional) Ollama local LLM test (commented)\n",
    "Example setup for running a local Ollama model. Currently disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4cb55a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from langchain_ollama import ChatOllama\n",
    "\n",
    "# llm = ChatOllama(\n",
    "#     model=\"llama3.2:3b\",\n",
    "#     temperature=0.2,\n",
    "#     num_predict=80,   # cap output tokens (big speedup)\n",
    "# )\n",
    "# resp = llm.invoke(\"Tell me a very short one-line joke about programmers.\")\n",
    "# print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202af664",
   "metadata": {},
   "source": [
    "## 3) Load PDF document (data ingestion)\n",
    "Loads `mlschool.pdf` using `PyPDFLoader` and creates one LangChain `Document` per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "73b0ff8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /Users/harshvardhan/Documents/Placements/Projects/Knowledge Base Search LLM/pdfs/mlschool.pdf\n",
      "Number of pages: 14\n",
      "First page preview: Learn to Build AI & Machine Learning\n",
      "Systems That Don't Suck\n",
      "A live, hands-on program that will help you become an order of magnitude\n",
      "better at building world-class AI/ML systems.\n",
      "This program is for developers looking to solve real-\n",
      "world problems using AI/ML.\n",
      "Most courses are boring, too academic,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = os.path.abspath(\"pdfs/mlschool.pdf\")\n",
    "print(\"Loading:\", pdf_path)\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "# return one Document per page\n",
    "pages = loader.load()\n",
    "pages\n",
    "\n",
    "print(f\"Number of pages: {len(pages)}\")\n",
    "print(\"First page preview:\", pages[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce642e70",
   "metadata": {},
   "source": [
    "## 4) Create the RAG prompt template\n",
    "Defines the instruction template used to answer questions using retrieved document context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29bf1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If the question can't\n",
      "be answered based on the context, say \"I don't know\".\n",
      "\n",
      "context : LangChain is a framework for developing applications powered by language models.\n",
      "Question : What is LangChain?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If the question can't\n",
    "be answered based on the context, say \"I don't know\".\n",
    "\n",
    "context : {context}\n",
    "Question : {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(\n",
    "    prompt.format(\n",
    "        context=\"LangChain is a framework for developing applications powered by language models.\",\n",
    "        question=\"What is LangChain?\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d442a",
   "metadata": {},
   "source": [
    "## 5) Quick prompt → LLM chain sanity check\n",
    "Tests the prompt + model pipeline on a small, manual context string to confirm the LLM call works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d842422b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Harsh Vardhan.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = prompt | model | StrOutputParser()\n",
    "print(chain.invoke({\"context\": \"the name i was given harsh vardhan\", \"question\": \"What is my name?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb8c03",
   "metadata": {},
   "source": [
    "## 6) Create embeddings + build vector store (indexing)\n",
    "Embeds the PDF pages using a sentence-transformer model and stores vectors for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7180e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    pages,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a4390",
   "metadata": {},
   "source": [
    "## 7) Create retriever + test retrieval\n",
    "Wraps the vector store as a retriever and verifies that relevant pages are being returned for a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2bf20510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:53:56+00:00', 'title': \"Building AI/ML Systems That Don't Suck\", 'moddate': '2025-12-19T05:53:56+00:00', 'source': '/Users/harshvardhan/Documents/Placements/Projects/Knowledge Base Search LLM/mlschool.pdf', 'total_pages': 14, 'page': 10, 'page_label': '11'}, page_content='Live sessions take place every Monday and Thursday. Office\\nhours take place on Wednesdays. Every session is recorded. You\\ncan attend live or watch the recorded version later.\\nHere are the upcoming cohorts:\\nCohort 21:February 2-February 19, 2026.10:00 AM EST\\nCohort 22:May 4-May 21, 2026.2:00 PM EDT\\nYou don\\'t have to wait for a specific cohort to join the program.\\nYou have lifetime access, so you can join any time and lock in the\\ncurrent price. The sooner you join, the cheaper it will be.\\n\"This is one of the best classes I\\'ve ever purchased over the internet.\\nSantiago is a terrific teacher. The ability he has to share knowledge is\\nfantastic. I recommend this course. Worth 10x what he\\'s charging.\"\\nSal DiStefano\\nFrequently Asked Questions\\n19/12/2025, 11:23 Building AI/ML Systems That Don\\'t Suck\\nhttps://www.ml.school 11/14'), Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:53:56+00:00', 'title': \"Building AI/ML Systems That Don't Suck\", 'moddate': '2025-12-19T05:53:56+00:00', 'source': '/Users/harshvardhan/Documents/Placements/Projects/Knowledge Base Search LLM/mlschool.pdf', 'total_pages': 14, 'page': 13, 'page_label': '14'}, page_content=\"I started this program in March 2023, and since then,\\nmore than 2,000 students have successfully\\ngraduated.\\nI can't wait to see you in class!\\nCopyright © 2025 Tideily LLC.\\nAll rights reserved.\\n19/12/2025, 11:23 Building AI/ML Systems That Don't Suck\\nhttps://www.ml.school 14/14\"), Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:53:56+00:00', 'title': \"Building AI/ML Systems That Don't Suck\", 'moddate': '2025-12-19T05:53:56+00:00', 'source': '/Users/harshvardhan/Documents/Placements/Projects/Knowledge Base Search LLM/mlschool.pdf', 'total_pages': 14, 'page': 1, 'page_label': '2'}, page_content=\"This is the class I wish I had taken when I started.\\n$500$300\\nNext cohort:February2 - 19, 2026\\nEnroll today and you'll getfree,lifetimeaccess to every\\npast and future cohort. You'll never pay another cent,\\never.\\nEnroll now\\nAlready a member?Sign in\\nWITH FORMER STUDENTS FROM\\nWhat You'll Learn\\n19/12/2025, 11:23 Building AI/ML Systems That Don't Suck\\nhttps://www.ml.school 2/14\"), Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36', 'creationdate': '2025-12-19T05:53:56+00:00', 'title': \"Building AI/ML Systems That Don't Suck\", 'moddate': '2025-12-19T05:53:56+00:00', 'source': '/Users/harshvardhan/Documents/Placements/Projects/Knowledge Base Search LLM/mlschool.pdf', 'total_pages': 14, 'page': 8, 'page_label': '9'}, page_content='\"I have learned a ton from Santiago in his class and it was actually what\\nhelped inspire me and get into the MLOps work that I\\'m doing now. Truly\\none of the most helpful online courses for doing real, full-scale machine\\nlearning.\"\\nBrian H. Hough\\nSoftware Engineer\\nWho Is This Program For?\\nThis is hands-on program for people willing to put in\\nthe work to build skills with real-world impact.\\nThis program is for software developers,data scientists,data\\nengineers, data analysts,technical managers, and anyone who\\nwants to use Artificial Intelligence and Machine Learning to solve\\nreal-world problems.\\nHere are the prerequisites to succeed in the program:\\nYou are not afraid of writing code. We\\'ll use Python, but\\nyou\\'ll be fine if you have experience with any other\\nlanguage.\\n19/12/2025, 11:23 Building AI/ML Systems That Don\\'t Suck\\nhttps://www.ml.school 9/14')]\n",
      "Retrieved: 4\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "docs = retriever.invoke(\"mlschool\")\n",
    "print(docs)\n",
    "print(\"Retrieved:\", len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b0f04",
   "metadata": {},
   "source": [
    "## 8) Build the full RAG chain (Retriever → Prompt → Groq LLM)\n",
    "Creates the end-to-end pipeline: retrieve context from PDF, format prompt, call Groq LLM, return plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c23187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. The context provided does not explicitly define what Machine Learning is. However, it does mention Machine Learning in various contexts, such as \"real-world AI and Machine Learning engineering skills\", \"building production-ready AI/ML systems\", and \"model-centric and data-centric AI\".\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Correctly define the LLM object\n",
    "# model = ChatGroq(\n",
    "#     groq_api_key=api_key,\n",
    "#     model_name=\"llama-3.1-8b-instant\",\n",
    "#     temperature=0.2\n",
    "# )\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke({\n",
    "    \"question\": \"What is Machine Learning?\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb4b2b",
   "metadata": {},
   "source": [
    "## 9) Batch questions loop\n",
    "Runs multiple questions through the RAG chain and prints each question and its answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3ba95807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is Machine Learning?How much does this course cost?\n",
      "Answer: Based on the provided context, I can answer the following questions:\n",
      "\n",
      "1. What is Machine Learning? \n",
      "Machine Learning is not explicitly defined in the provided context. However, it is mentioned as a key topic in the course \"Building AI/ML Systems That Don't Suck\". \n",
      "\n",
      "2. How much does this course cost?\n",
      "The course costs $500, with a discounted price of $300.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = [\n",
    "    # \"what is this project about?\"\n",
    "    # \"What services does Unthinkable Solutions provide?\"\n",
    "    # \"What technologies or tech stack do they specialize in?\"\n",
    "    # \"Where is the company located?\"\n",
    "    # \"Can i use Fronted technologies like Reactjs with their services?\"\n",
    "    # \"\"\n",
    "    # \"what is the purpose of this course?\"\n",
    "    # \"How many modules are there in this course?\"\n",
    "    # \"How many hours of content are there in this course?\"\n",
    "    # \"Is there a program certificate provided upon completion?\"\n",
    "    # \"What is the overview of this course?\"\n",
    "\n",
    "    \"What is Machine Learning?\"\n",
    "    # \"What are the prerequisites for enrolling in this course?\"\n",
    "    # # \"What Programing languages are covered in this course?\"\n",
    "    \"How much does this course cost?\"\n",
    "]\n",
    "\n",
    "for q in question:\n",
    "    print(\"Question:\", q)\n",
    "    print(\"Answer:\", chain.invoke({\n",
    "        \"question\": q\n",
    "    }))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d82bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
